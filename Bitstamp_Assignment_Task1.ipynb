{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitstamp Assesment Test\n",
    "## Task 1: Where are my assets?\n",
    "\n",
    "Welcome to crypto! The Product team is seeking insights into the performance of our lending product. Your mission is to:\n",
    "\n",
    "1. Clean (if needed) and enrich the attached data (*task_1_earn.csv*) â€“ end goal is having clean table which can be\n",
    "easily used (without any manipulation) for any kind of analytics. The presented data includes all completed lending\n",
    "withdrawals (when a user makes a request to stop lending). Add yearweek and yearmonth columns and any other\n",
    "that will be useful to end users.\n",
    "Definitions:\n",
    "    - **User_Id** is the id of user\n",
    "    - **Id** is the identifier of the withdrawal request\n",
    "    - **Requested_at** means when the user made a request to unlend\n",
    "    - **Finished_at** means when the lending provider completed the lending and user got the funds\n",
    "\n",
    "2. Prepare an analysis of the lending product with the data you have so the product team will be able to identify if we\n",
    "have any issues with our lending provider. Include numbers and graphs and don't forget to write key findings.\n",
    "    -  Identify key trends, patterns, and potential issues with the lending provider.\n",
    "\n",
    "3. Based on your analysis:\n",
    "    - **Identify opportunities** to improve the **performance** and **reliability** of our lending provider.\n",
    "    - Suggest actionable **recommendations** for the Product team to address these issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import libraries\n",
    "Import main libraries for analysing data and visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data\n",
    "\n",
    "Import data from the *task_1_earn.csv* file. The tester shoul change the **file_path_1** variable to the path to the file, if it is not already in the same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>currency</th>\n",
       "      <th>user_id</th>\n",
       "      <th>id</th>\n",
       "      <th>amount_native</th>\n",
       "      <th>amount_usd</th>\n",
       "      <th>requested_at</th>\n",
       "      <th>finished_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BTC</td>\n",
       "      <td>44017161</td>\n",
       "      <td>117200</td>\n",
       "      <td>17.449950</td>\n",
       "      <td>1234.825630</td>\n",
       "      <td>2020-11-24 22:59:35</td>\n",
       "      <td>2020-01-25 14:00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MATIC</td>\n",
       "      <td>46740482</td>\n",
       "      <td>117197</td>\n",
       "      <td>17.450786</td>\n",
       "      <td>546.674743</td>\n",
       "      <td>2020-01-24 22:33:10</td>\n",
       "      <td>2020-01-25 02:00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PEPE</td>\n",
       "      <td>46489105</td>\n",
       "      <td>117194</td>\n",
       "      <td>17.446612</td>\n",
       "      <td>556.810541</td>\n",
       "      <td>2020-01-24 22:12:18</td>\n",
       "      <td>2020-01-25 02:00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PEPE</td>\n",
       "      <td>46117080</td>\n",
       "      <td>117193</td>\n",
       "      <td>17.446693</td>\n",
       "      <td>1045.785866</td>\n",
       "      <td>2020-01-24 22:03:20</td>\n",
       "      <td>2020-01-25 02:00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AVAX</td>\n",
       "      <td>47626266</td>\n",
       "      <td>117191</td>\n",
       "      <td>17.454170</td>\n",
       "      <td>653.661058</td>\n",
       "      <td>2020-01-24 22:01:30</td>\n",
       "      <td>2020-01-25 02:00:41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  currency   user_id      id  amount_native   amount_usd         requested_at  \\\n",
       "0      BTC  44017161  117200      17.449950  1234.825630  2020-11-24 22:59:35   \n",
       "1    MATIC  46740482  117197      17.450786   546.674743  2020-01-24 22:33:10   \n",
       "2     PEPE  46489105  117194      17.446612   556.810541  2020-01-24 22:12:18   \n",
       "3     PEPE  46117080  117193      17.446693  1045.785866  2020-01-24 22:03:20   \n",
       "4     AVAX  47626266  117191      17.454170   653.661058  2020-01-24 22:01:30   \n",
       "\n",
       "           finished_at  \n",
       "0  2020-01-25 14:00:02  \n",
       "1  2020-01-25 02:00:20  \n",
       "2  2020-01-25 02:00:19  \n",
       "3  2020-01-25 02:00:19  \n",
       "4  2020-01-25 02:00:41  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV file into a DataFrame /w check for file existence\n",
    "file_path_1 = 'Data/task_1_earn.csv'  # Path to the CSV file (change if the testers file is in a different directory)\n",
    "try:\n",
    "    df_1 = pd.read_csv(file_path_1)\n",
    "    print(\"Data loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found at {file_path_1}. Please check the path.\")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df_1.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the data\n",
    "\n",
    "Upon inspection we can see that some of the **requested_at** or **finished_at** inputs have invalid values (e. g. requested_at date being February $30^{\\text{th}}$). \n",
    "\n",
    "We prepare functions that check if the date is valid (*is_valid_date*) and then correct the date (*fix_invalid_date*). The date is corrected to the last valid date before it for values of **requested_at** (e. g. 2020-4-31 is changed to 2020-04-30), and it is corrected to the first valid date after it for values of **finished_at**. All the changes to dates are logged into the data_correction_log.txt file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid dates fixed. Changes logged to 'date_correction_log.txt'.\n"
     ]
    }
   ],
   "source": [
    "# Function to adjust invalid dates\n",
    "def fix_invalid_date(date_str, adjust='previous'):\n",
    "    # Split the date and time parts\n",
    "    date_part, time_part = date_str.split(' ')\n",
    "    year, month, day = map(int, date_part.split('-'))\n",
    "    time_str = time_part\n",
    "\n",
    "    # Adjust the data backwards for requested_at -> parameter 'previous'\n",
    "    if adjust == 'previous':\n",
    "        # Move backward until a valid date is found (e.g. 2020-02-31 -> 2020-02-30 -> 2020-02-29)\n",
    "        while True:\n",
    "            try:\n",
    "                new_date = datetime(year, month, day)\n",
    "                break\n",
    "            except ValueError:\n",
    "                day -= 1\n",
    "\n",
    "    # Adjust the data forward for finished_at -> parameter 'next'\n",
    "    elif adjust == 'next':\n",
    "        while True:\n",
    "            try:\n",
    "                new_date = datetime(year, month, day)\n",
    "                break\n",
    "            except ValueError:\n",
    "                # Set the date to the first day of the next month\n",
    "                month += 1\n",
    "                day = 1\n",
    "\n",
    "    # Return the fixed date with the original time\n",
    "    return new_date.strftime('%Y-%m-%d') + ' ' + time_str\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "\n",
    "# Helper function to parse date flexibly\n",
    "def is_valid_date(date_str):\n",
    "    try:\n",
    "        # Try parsing with fractional seconds\n",
    "        datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S.%f')\n",
    "        return True\n",
    "    except ValueError:\n",
    "        try:\n",
    "            # Try parsing without fractional seconds\n",
    "            datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "\n",
    "# =========================================================================================\n",
    "\n",
    "# Initialize a log list to capture changes\n",
    "log_entries = []\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "\n",
    "# Process 'requested_at' and 'finished_at' columns\n",
    "for idx, row in df_1.iterrows():\n",
    "    # Process 'requested_at'\n",
    "    original_requested_at = row['requested_at']\n",
    "    if isinstance(original_requested_at, str):\n",
    "        if not is_valid_date(original_requested_at):\n",
    "            new_requested_at = fix_invalid_date(original_requested_at, adjust='previous')\n",
    "            df_1.at[idx, 'requested_at'] = new_requested_at\n",
    "            log_entries.append(\n",
    "                f\"Invalid requested_at value for input id: {row['id']}. \"\n",
    "                f\"Value changed from {original_requested_at} to {new_requested_at}\"\n",
    "            )\n",
    "\n",
    "    # Process 'finished_at'\n",
    "    original_finished_at = row['finished_at']\n",
    "    if isinstance(original_finished_at, str):\n",
    "        if not is_valid_date(original_finished_at):\n",
    "            new_finished_at = fix_invalid_date(original_finished_at, adjust='next')\n",
    "            df_1.at[idx, 'finished_at'] = new_finished_at\n",
    "            log_entries.append(\n",
    "                f\"Invalid finished_at value for input id: {row['id']}. \"\n",
    "                f\"Value changed from {original_finished_at} to {new_finished_at}\"\n",
    "            )\n",
    "\n",
    "# -----------------------------------------------------------------------------------------\n",
    "\n",
    "# Save the log entries to a file\n",
    "with open('Outputs/data_correction_log.txt', 'w') as log_file:\n",
    "    for entry in log_entries:\n",
    "        log_file.write(entry + '\\n')\n",
    "\n",
    "print(\"Invalid dates fixed. Changes logged to 'date_correction_log.txt'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  currency   user_id      id  amount_native   amount_usd        requested_at  \\\n",
      "0      BTC  44017161  117200      17.449950  1234.825630 2020-11-24 22:59:35   \n",
      "1    MATIC  46740482  117197      17.450786   546.674743 2020-01-24 22:33:10   \n",
      "2     PEPE  46489105  117194      17.446612   556.810541 2020-01-24 22:12:18   \n",
      "3     PEPE  46117080  117193      17.446693  1045.785866 2020-01-24 22:03:20   \n",
      "4     AVAX  47626266  117191      17.454170   653.661058 2020-01-24 22:01:30   \n",
      "\n",
      "          finished_at yearweek yearmonth  time_to_complete  possible_error  \\\n",
      "0 2020-01-25 14:00:02  2020-47   2020-11      -7304.992500            True   \n",
      "1 2020-01-25 02:00:20  2020-03   2020-01          3.452778           False   \n",
      "2 2020-01-25 02:00:19  2020-03   2020-01          3.800278           False   \n",
      "3 2020-01-25 02:00:19  2020-03   2020-01          3.949722           False   \n",
      "4 2020-01-25 02:00:41  2020-03   2020-01          3.986389           False   \n",
      "\n",
      "   conversion_rate  \n",
      "0        70.763847  \n",
      "1        31.326655  \n",
      "2        31.915110  \n",
      "3        59.941781  \n",
      "4        37.450137  \n"
     ]
    }
   ],
   "source": [
    "# Convert 'requested_at' and 'finished_at' columns to datetime after all fixes\n",
    "df_1['requested_at'] = pd.to_datetime(df_1['requested_at'], errors='coerce')\n",
    "df_1['finished_at'] = pd.to_datetime(df_1['finished_at'], errors='coerce')\n",
    "\n",
    "# Ensure there are no NaT values after conversion (log and handle if necessary)\n",
    "if df_1['requested_at'].isnull().any() or df_1['finished_at'].isnull().any():\n",
    "    print(\"Warning: Some dates could not be converted to datetime.\")\n",
    "\n",
    "# Add yearweek and yearmonth columns\n",
    "df_1['yearweek'] = df_1['requested_at'].dt.strftime('%Y-%U')\n",
    "df_1['yearmonth'] = df_1['requested_at'].dt.strftime('%Y-%m')\n",
    "\n",
    "# Add time_to_complete column (in hours)\n",
    "df_1['time_to_complete'] = (df_1['finished_at'] - df_1['requested_at']).dt.total_seconds() / 3600\n",
    "\n",
    "# Add possible_error column (where time_to_complete is negative)\n",
    "df_1['possible_error'] = df_1['time_to_complete'] < 0\n",
    "\n",
    "# Add conversion_rate column (amount_usd / amount_native)\n",
    "df_1['conversion_rate'] = df_1['amount_usd'] / df_1['amount_native']\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df_1.head())\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "df_1.to_csv('Outputs/task_1_earn_cleaned.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
